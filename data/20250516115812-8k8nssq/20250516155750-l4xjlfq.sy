{"ID":"20250516155750-l4xjlfq","Spec":"1","Type":"NodeDocument","Properties":{"id":"20250516155750-l4xjlfq","title":"实验对象","type":"doc","updated":"20250529160606"},"Children":[{"ID":"20250516155954-rqvexie","Type":"NodeHeading","HeadingLevel":1,"Properties":{"id":"20250516155954-rqvexie","updated":"20250516165346"},"Children":[{"Type":"NodeText","Data":"相关文献中的实验对象"}]},{"ID":"20250516155955-k76ark7","Type":"NodeList","ListData":{},"Properties":{"id":"20250516155955-k76ark7","updated":"20250516162557"},"Children":[{"ID":"20250516160248-k5e06bx","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250516160248-k5e06bx","updated":"20250516162557"},"Children":[{"ID":"20250516160248-h4ldvgg","Type":"NodeParagraph","Properties":{"id":"20250516160248-h4ldvgg","updated":"20250516161954"},"Children":[{"Type":"NodeText","Data":"DeepPerform: An Efficient Approach for Performance Testing of Resource-Constrained Neural Networks - ASE-2022"}]},{"ID":"20250516162513-fyyk2k6","Type":"NodeList","ListData":{},"Properties":{"id":"20250516162513-fyyk2k6","updated":"20250516162557"},"Children":[{"ID":"20250516162512-3yqv3ra","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250516162512-3yqv3ra","updated":"20250516162557"},"Children":[{"ID":"20250516162512-ft14eww","Type":"NodeParagraph","Properties":{"id":"20250516162512-ft14eww","updated":"20250516162557"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"BaseLine"},{"Type":"NodeText","Data":"：ILFO，DeepPerform(本文工具)"}]}]}]}]}]},{"ID":"20250516162012-3cubej0","Type":"NodeTable","TableAligns":[0,0,0,0],"Properties":{"colgroup":"|||","id":"20250516162012-3cubej0","updated":"20250516165341"},"Children":[{"Type":"NodeTableHead","Data":"thead","Children":[{"Type":"NodeTableRow","Data":"tr","Children":[{"Type":"NodeTableCell","Data":"th","Children":[{"Type":"NodeText","Data":"序号"}]},{"Type":"NodeTableCell","Data":"th","Children":[{"Type":"NodeText","Data":"数据集"}]},{"Type":"NodeTableCell","Data":"th","Children":[{"Type":"NodeText","Data":"模型名称"}]},{"Type":"NodeTableCell","Data":"th","Children":[{"Type":"NodeText","Data":"模型特点说明("},{"Type":"NodeTextMark","Properties":{"style":"background-color: var(--b3-card-warning-background); color: var(--b3-card-warning-color);"},"TextMarkType":"text","TextMarkTextContent":"AdNN"},{"Type":"NodeKramdownSpanIAL","Data":"{: style=\"background-color: var(--b3-card-warning-background); color: var(--b3-card-warning-color);\"}"},{"Type":"NodeText","Data":":针对不同的输入选择性地激活部分计算单元(例如卷积层、全连接层等)，而不是整个单元进行计算。部分单元选择机制使得AdNNs能够在资源受限的设备上实现实时预测。)"}]}]}]},{"Type":"NodeTableRow","Data":"tr","Children":[{"Type":"NodeTableCell","Data":"td","Children":[{"Type":"NodeText","Data":"1"}]},{"Type":"NodeTableCell","Data":"td","Children":[{"Type":"NodeText","Data":"CIFAR-10"}]},{"Type":"NodeTableCell","Data":"td","Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"SkipNet"}]},{"Type":"NodeTableCell","Data":"td","Children":[{"Type":"NodeText","Data":"使用强化学习控制跳过网络中的冗余块，属于 conditional-skipping 类型 AdNN。"}]}]},{"Type":"NodeTableRow","Data":"tr","Children":[{"Type":"NodeTableCell","Data":"td","Children":[{"Type":"NodeText","Data":"2"}]},{"Type":"NodeTableCell","Data":"td","Children":[{"Type":"NodeText","Data":"CIFAR-10"}]},{"Type":"NodeTableCell","Data":"td","Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"BlockDrop"}]},{"Type":"NodeTableCell","Data":"td","Children":[{"Type":"NodeText","Data":"训练一个策略网络动态激活部分网络模块，以减少计算量，也是 conditional-skipping 类型。"}]}]},{"Type":"NodeTableRow","Data":"tr","Children":[{"Type":"NodeTableCell","Data":"td","Children":[{"Type":"NodeText","Data":"3"}]},{"Type":"NodeTableCell","Data":"td","Children":[{"Type":"NodeText","Data":"CIFAR-100"}]},{"Type":"NodeTableCell","Data":"td","Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"RaNet"}]},{"Type":"NodeTableCell","Data":"td","Children":[{"Type":"NodeText","Data":"同时调整输入图像分辨率与网络深度，优化性能与精度，属于 early-termination 类型。"}]}]},{"Type":"NodeTableRow","Data":"tr","Children":[{"Type":"NodeTableCell","Data":"td","Children":[{"Type":"NodeText","Data":"4"}]},{"Type":"NodeTableCell","Data":"td","Children":[{"Type":"NodeText","Data":"CIFAR-100"}]},{"Type":"NodeTableCell","Data":"td","Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"DeepShallow"}]},{"Type":"NodeTableCell","Data":"td","Children":[{"Type":"NodeText","Data":"根据输入动态选择使用浅层或深层网络，具备 early-termination 能力。"}]}]},{"Type":"NodeTableRow","Data":"tr","Children":[{"Type":"NodeTableCell","Data":"td","Children":[{"Type":"NodeText","Data":"5"}]},{"Type":"NodeTableCell","Data":"td","Children":[{"Type":"NodeText","Data":"SVHN"}]},{"Type":"NodeTableCell","Data":"td","Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"DeepShallow"}]},{"Type":"NodeTableCell","Data":"td","Children":[{"Type":"NodeText","Data":"同上，但在不同数据集上评估，以检验模型的通用性和性能。"}]}]}]},{"ID":"20250516165346-15mjjh1","Type":"NodeParagraph","Properties":{"id":"20250516165346-15mjjh1","updated":"20250516165346"}},{"ID":"20250516155802-d11ywtc","Type":"NodeHeading","HeadingLevel":1,"Properties":{"id":"20250516155802-d11ywtc","updated":"20250516155923"},"Children":[{"Type":"NodeText","Data":"深度学习模型类别"}]},{"ID":"20250516155755-c2qcm3x","Type":"NodeHeading","HeadingLevel":4,"Properties":{"id":"20250516155755-c2qcm3x","updated":"20250516155923"},"Children":[{"Type":"NodeText","Data":"1. 前馈神经网络（Feedforward Neural Networks）"}]},{"ID":"20250516155755-y0h8ynl","Type":"NodeList","ListData":{},"Properties":{"id":"20250516155755-y0h8ynl","updated":"20250516155755"},"Children":[{"ID":"20250516155755-py4574s","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250516155755-py4574s","updated":"20250516155755"},"Children":[{"ID":"20250516155755-aevqjml","Type":"NodeParagraph","Properties":{"id":"20250516155755-aevqjml","updated":"20250516155755"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"多层感知机 (MLP, Multilayer Perceptron)"},{"Type":"NodeText","Data":"\n由若干全连接层（Dense Layer）和非线性激活函数组成，最基本的深度学习模型，适用于结构化数据分类、回归等。"}]}]},{"ID":"20250516155755-8n755vc","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250516155755-8n755vc","updated":"20250516155755"},"Children":[{"ID":"20250516155755-cikfrqs","Type":"NodeParagraph","Properties":{"id":"20250516155755-cikfrqs","updated":"20250516155755"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"残差网络 (ResNet)"},{"Type":"NodeText","Data":"\n引入“残差连接”（skip connection）解决深层网络梯度消失/退化问题，代表作有 ResNet-50/101/152 等。"}]}]},{"ID":"20250516155755-5d6teh2","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250516155755-5d6teh2","updated":"20250516155755"},"Children":[{"ID":"20250516155755-tub50ky","Type":"NodeParagraph","Properties":{"id":"20250516155755-tub50ky","updated":"20250516155755"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"密集连接网络 (DenseNet)"},{"Type":"NodeText","Data":"\n每层与之前所有层连接，强化特征复用和梯度传递，参数更高效。"}]}]}]},{"ID":"20250516155755-fevov1a","Type":"NodeThematicBreak","Properties":{"id":"20250516155755-fevov1a","updated":"20250516155755"}},{"ID":"20250516155755-syrlybf","Type":"NodeHeading","HeadingLevel":4,"Properties":{"id":"20250516155755-syrlybf","updated":"20250516155929"},"Children":[{"Type":"NodeText","Data":"2. 卷积神经网络（Convolutional Neural Networks, CNN）"}]},{"ID":"20250516155755-7y2x19v","Type":"NodeList","ListData":{},"Properties":{"id":"20250516155755-7y2x19v","updated":"20250516155755"},"Children":[{"ID":"20250516155755-az84k09","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250516155755-az84k09","updated":"20250516155755"},"Children":[{"ID":"20250516155755-q664ciu","Type":"NodeParagraph","Properties":{"id":"20250516155755-q664ciu","updated":"20250516155755"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"经典卷积网络"},{"Type":"NodeText","Data":"：LeNet、AlexNet、VGG\n以连续卷积 + 池化 + 全连接层为主，开创了图像识别时代。"}]}]},{"ID":"20250516155755-nu5f0gv","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250516155755-nu5f0gv","updated":"20250516155755"},"Children":[{"ID":"20250516155755-m8q3vy4","Type":"NodeParagraph","Properties":{"id":"20250516155755-m8q3vy4","updated":"20250516155755"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"Inception 系列（GoogLeNet/Inception-v3、v4）"},{"Type":"NodeText","Data":"\n在同一层内并行多种大小卷积核，提高网络宽度与多尺度特征表达能力。"}]}]},{"ID":"20250516155755-k5gxeh9","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250516155755-k5gxeh9","updated":"20250516155755"},"Children":[{"ID":"20250516155755-iod0exz","Type":"NodeParagraph","Properties":{"id":"20250516155755-iod0exz","updated":"20250516155755"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"MobileNet / ShuffleNet"},{"Type":"NodeText","Data":"\n为移动/嵌入式设备设计的轻量化网络，采用深度可分离卷积、组卷积等技术。"}]}]},{"ID":"20250516155755-ac55q67","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250516155755-ac55q67","updated":"20250516155755"},"Children":[{"ID":"20250516155755-1tzadxk","Type":"NodeParagraph","Properties":{"id":"20250516155755-1tzadxk","updated":"20250516155755"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"EfficientNet"},{"Type":"NodeText","Data":"\n系统化地在宽度、深度和分辨率三维度上复合缩放，性能与效率平衡最佳。"}]}]}]},{"ID":"20250516155755-xi5yslu","Type":"NodeThematicBreak","Properties":{"id":"20250516155755-xi5yslu","updated":"20250516155755"}},{"ID":"20250516155755-1k5hwa0","Type":"NodeHeading","HeadingLevel":4,"Properties":{"id":"20250516155755-1k5hwa0","updated":"20250516155755"},"Children":[{"Type":"NodeText","Data":"3. 序列模型（Recurrent \u0026 Attention-based Networks）"}]},{"ID":"20250516155755-w7gsmve","Type":"NodeList","ListData":{},"Properties":{"id":"20250516155755-w7gsmve","updated":"20250516155755"},"Children":[{"ID":"20250516155755-8vfp9vl","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250516155755-8vfp9vl","updated":"20250516155755"},"Children":[{"ID":"20250516155755-twh4dfo","Type":"NodeParagraph","Properties":{"id":"20250516155755-twh4dfo","updated":"20250516155755"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"循环神经网络 (RNN)"},{"Type":"NodeText","Data":"\n适合处理序列数据，但易梯度消失。"}]}]},{"ID":"20250516155755-d3cr83b","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250516155755-d3cr83b","updated":"20250516155755"},"Children":[{"ID":"20250516155755-ohgqhfg","Type":"NodeParagraph","Properties":{"id":"20250516155755-ohgqhfg","updated":"20250516155755"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"长短期记忆网络 (LSTM)"},{"Type":"NodeText","Data":" / "},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"门控循环单元 (GRU)"},{"Type":"NodeText","Data":"\n引入遗忘门、输入门、输出门等结构，有效建模长程依赖。"}]}]},{"ID":"20250516155755-9qv9enk","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250516155755-9qv9enk","updated":"20250516155755"},"Children":[{"ID":"20250516155755-j3jtas4","Type":"NodeParagraph","Properties":{"id":"20250516155755-j3jtas4","updated":"20250516155755"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"Transformer 及其变体"}]},{"ID":"20250516155755-cpubpmz","Type":"NodeList","ListData":{},"Properties":{"id":"20250516155755-cpubpmz","updated":"20250516155755"},"Children":[{"ID":"20250516155755-m6u9wey","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250516155755-m6u9wey","updated":"20250516155755"},"Children":[{"ID":"20250516155755-0yxa0ci","Type":"NodeParagraph","Properties":{"id":"20250516155755-0yxa0ci","updated":"20250516155755"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"原生 Transformer"},{"Type":"NodeText","Data":"：基于自注意力（Self-Attention）机制，彻底并行化序列建模，开创 NLP “预训练+微调”时代。"}]}]},{"ID":"20250516155755-s6ons9d","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250516155755-s6ons9d","updated":"20250516155755"},"Children":[{"ID":"20250516155755-9xvlixq","Type":"NodeParagraph","Properties":{"id":"20250516155755-9xvlixq","updated":"20250516155755"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"BERT / RoBERTa / ALBERT"},{"Type":"NodeText","Data":"：双向 Transformer 预训练模型，强于文本理解任务；"}]}]},{"ID":"20250516155755-vjbi7c6","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250516155755-vjbi7c6","updated":"20250516155755"},"Children":[{"ID":"20250516155755-v1yw3bg","Type":"NodeParagraph","Properties":{"id":"20250516155755-v1yw3bg","updated":"20250516155755"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"GPT 系列"},{"Type":"NodeText","Data":"：单向自回归模型，擅长文本生成；"}]}]},{"ID":"20250516155755-pmulwva","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250516155755-pmulwva","updated":"20250516155755"},"Children":[{"ID":"20250516155755-qgwxh21","Type":"NodeParagraph","Properties":{"id":"20250516155755-qgwxh21","updated":"20250516155755"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"Vision Transformer (ViT)"},{"Type":"NodeText","Data":"：将图像划分为 Patch 后输入 Transformer，逐步在视觉领域普及。"}]}]}]}]}]},{"ID":"20250516155755-5u6w35m","Type":"NodeThematicBreak","Properties":{"id":"20250516155755-5u6w35m","updated":"20250516155755"}},{"ID":"20250516155755-h2fc6hu","Type":"NodeHeading","HeadingLevel":4,"Properties":{"id":"20250516155755-h2fc6hu","updated":"20250516155755"},"Children":[{"Type":"NodeText","Data":"4. 自编码与生成模型（Autoencoders \u0026 Generative Models）"}]},{"ID":"20250516155755-forhwzq","Type":"NodeList","ListData":{},"Properties":{"id":"20250516155755-forhwzq","updated":"20250516155755"},"Children":[{"ID":"20250516155755-xac7wgm","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250516155755-xac7wgm","updated":"20250516155755"},"Children":[{"ID":"20250516155755-hkidqp9","Type":"NodeParagraph","Properties":{"id":"20250516155755-hkidqp9","updated":"20250516155755"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"自编码器 (Autoencoder)"},{"Type":"NodeText","Data":"\n由编码器和解码器组成，用于无监督特征学习、降维、去噪。"}]}]},{"ID":"20250516155755-faoqbz2","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250516155755-faoqbz2","updated":"20250516155755"},"Children":[{"ID":"20250516155755-0hjruw6","Type":"NodeParagraph","Properties":{"id":"20250516155755-0hjruw6","updated":"20250516155755"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"变分自编码器 (VAE, Variational Autoencoder)"},{"Type":"NodeText","Data":"\n在原始自编码器中加入概率分布假设，可进行连续潜空间的采样及重构。"}]}]},{"ID":"20250516155755-61iip3x","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250516155755-61iip3x","updated":"20250516155755"},"Children":[{"ID":"20250516155755-ddkccgg","Type":"NodeParagraph","Properties":{"id":"20250516155755-ddkccgg","updated":"20250516155755"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"生成对抗网络 (GAN, Generative Adversarial Network)"},{"Type":"NodeText","Data":"\n包括生成器和判别器，两者对抗式训练。衍生出 DCGAN、WGAN、StyleGAN 等，图像生成效果显著。"}]}]},{"ID":"20250516155755-kamf391","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250516155755-kamf391","updated":"20250516155755"},"Children":[{"ID":"20250516155755-rrp5xhg","Type":"NodeParagraph","Properties":{"id":"20250516155755-rrp5xhg","updated":"20250516155755"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"归一化流 (Normalizing Flows)"},{"Type":"NodeText","Data":"\n通过可逆变换构造精确可计算似然的生成模型，如 RealNVP、Glow；"}]}]},{"ID":"20250516155755-wlim45g","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250516155755-wlim45g","updated":"20250516155755"},"Children":[{"ID":"20250516155755-11i80dl","Type":"NodeParagraph","Properties":{"id":"20250516155755-11i80dl","updated":"20250516155755"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"扩散模型 (Diffusion Models)"},{"Type":"NodeText","Data":"\n逐步向噪声添加/去噪，代表有 DDPM、Score-Based Models，在高质量图像生成上与 GAN 竞争。"}]}]}]},{"ID":"20250516155755-gdvqms1","Type":"NodeThematicBreak","Properties":{"id":"20250516155755-gdvqms1","updated":"20250516155755"}},{"ID":"20250516155755-nonn8uq","Type":"NodeHeading","HeadingLevel":4,"Properties":{"id":"20250516155755-nonn8uq","updated":"20250516155755"},"Children":[{"Type":"NodeText","Data":"5. 图神经网络（Graph Neural Networks, GNN）"}]},{"ID":"20250516155755-qfvemjw","Type":"NodeList","ListData":{},"Properties":{"id":"20250516155755-qfvemjw","updated":"20250516155755"},"Children":[{"ID":"20250516155755-kx9ww5v","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250516155755-kx9ww5v","updated":"20250516155755"},"Children":[{"ID":"20250516155755-t3jyj54","Type":"NodeParagraph","Properties":{"id":"20250516155755-t3jyj54","updated":"20250516155755"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"图卷积网络 (GCN, Graph Convolutional Network)"},{"Type":"NodeText","Data":"\n将卷积操作扩展到图结构，常用于节点分类、图分类。"}]}]},{"ID":"20250516155755-1pxxxa2","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250516155755-1pxxxa2","updated":"20250516155755"},"Children":[{"ID":"20250516155755-ck1e8mf","Type":"NodeParagraph","Properties":{"id":"20250516155755-ck1e8mf","updated":"20250516155755"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"图注意力网络 (GAT, Graph Attention Network)"},{"Type":"NodeText","Data":"\n在邻居聚合时引入注意力机制，自动学习邻居权重。"}]}]},{"ID":"20250516155755-a155nkx","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250516155755-a155nkx","updated":"20250516155755"},"Children":[{"ID":"20250516155755-vx0raxh","Type":"NodeParagraph","Properties":{"id":"20250516155755-vx0raxh","updated":"20250516155755"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"消息传递网络 (MPNN, Message Passing Neural Network)"},{"Type":"NodeText","Data":"\n更通用的图信息传播框架，包含许多衍生模型。"}]}]}]},{"ID":"20250516155755-uh30mfl","Type":"NodeThematicBreak","Properties":{"id":"20250516155755-uh30mfl","updated":"20250516155755"}},{"ID":"20250516155755-3f6cmy8","Type":"NodeHeading","HeadingLevel":4,"Properties":{"id":"20250516155755-3f6cmy8","updated":"20250516155755"},"Children":[{"Type":"NodeText","Data":"6. 强化学习网络（Reinforcement Learning Models）"}]},{"ID":"20250516155755-4pvkd34","Type":"NodeList","ListData":{},"Properties":{"id":"20250516155755-4pvkd34","updated":"20250516155755"},"Children":[{"ID":"20250516155755-okey7yl","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250516155755-okey7yl","updated":"20250516155755"},"Children":[{"ID":"20250516155755-05mod13","Type":"NodeParagraph","Properties":{"id":"20250516155755-05mod13","updated":"20250516155755"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"深度 Q 网络 (DQN)"},{"Type":"NodeText","Data":"\n将 Q-learning 与深度网络结合，适合离散动作空间。"}]}]},{"ID":"20250516155755-heclsza","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250516155755-heclsza","updated":"20250516155755"},"Children":[{"ID":"20250516155755-c2szbnf","Type":"NodeParagraph","Properties":{"id":"20250516155755-c2szbnf","updated":"20250516155755"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"策略梯度方法 (Policy Gradient)"},{"Type":"NodeText","Data":"\n直接参数化策略网络并优化预期奖励；有 REINFORCE、A2C/A3C、PPO 等。"}]}]},{"ID":"20250516155755-bs50xwv","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250516155755-bs50xwv","updated":"20250516155755"},"Children":[{"ID":"20250516155755-m3mhiu5","Type":"NodeParagraph","Properties":{"id":"20250516155755-m3mhiu5","updated":"20250516155755"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"Actor-Critic 架构"},{"Type":"NodeText","Data":"\n同时学习策略（Actor）与价值（Critic），兼具稳定性与效率。"}]}]}]},{"ID":"20250516155755-3ewtpho","Type":"NodeThematicBreak","Properties":{"id":"20250516155755-3ewtpho","updated":"20250516155755"}},{"ID":"20250516155755-fu7hh10","Type":"NodeHeading","HeadingLevel":4,"Properties":{"id":"20250516155755-fu7hh10","updated":"20250526173235"},"Children":[{"Type":"NodeText","Data":"7. 其他前沿方向"}]},{"ID":"20250516155755-08iomvx","Type":"NodeList","ListData":{},"Properties":{"id":"20250516155755-08iomvx","updated":"20250516155755"},"Children":[{"ID":"20250516155755-hi75t17","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250516155755-hi75t17","updated":"20250516155755"},"Children":[{"ID":"20250516155755-khmfmrc","Type":"NodeParagraph","Properties":{"id":"20250516155755-khmfmrc","updated":"20250516155755"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"Capsule Network (CapsNet)"},{"Type":"NodeText","Data":"\n捕捉实体与部件的空间关系，试图克服 CNN 的平移不变局限。"}]}]},{"ID":"20250516155755-53wmcg0","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250516155755-53wmcg0","updated":"20250516155755"},"Children":[{"ID":"20250516155755-9z4hhpe","Type":"NodeParagraph","Properties":{"id":"20250516155755-9z4hhpe","updated":"20250516155755"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"自监督学习模型"},{"Type":"NodeText","Data":"\n如 SimCLR、MoCo、BYOL，通过构造预训练任务学习通用表征。"}]}]},{"ID":"20250516155755-78w22xe","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250516155755-78w22xe","updated":"20250516155755"},"Children":[{"ID":"20250516155755-mkik293","Type":"NodeParagraph","Properties":{"id":"20250516155755-mkik293","updated":"20250516155755"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"多模态模型"},{"Type":"NodeText","Data":"\n如 CLIP（图文）、DALL·E（文本→图像）、Flamingo（视觉+语言），融合不同模态信息。"}]}]},{"ID":"20250516155755-i6ow2zl","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250516155755-i6ow2zl","updated":"20250516155755"},"Children":[{"ID":"20250516155755-hmfk1h9","Type":"NodeParagraph","Properties":{"id":"20250516155755-hmfk1h9","updated":"20250516155755"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"超网络（Hypernetworks）与神经架构搜索（NAS）"},{"Type":"NodeText","Data":"\n自动化生成模型结构或参数，提高模型设计效率。"}]}]}]},{"ID":"20250526173228-5tg31bk","Type":"NodeParagraph","Properties":{"id":"20250526173228-5tg31bk","updated":"20250526173228"}},{"ID":"20250526173228-n9wluf3","Type":"NodeHeading","HeadingLevel":1,"Properties":{"id":"20250526173228-n9wluf3","updated":"20250526173408"},"Children":[{"Type":"NodeText","Data":"如何评估深度学习模型"}]},{"ID":"20250526173241-8pnjcvp","Type":"NodeParagraph","Properties":{"id":"20250526173241-8pnjcvp","updated":"20250526173408"},"Children":[{"Type":"NodeText","Data":"在评估深度模型时，通常可以从“效果”、“效率”与“资源消耗”三大维度来收集性能指标。这里将“效果”作为功能测试结果，“效率”与“资源消耗”作为性能测试结果。"}]},{"ID":"20250526173241-v5cjm3a","Type":"NodeThematicBreak","Properties":{"id":"20250526173241-v5cjm3a","updated":"20250526173241"}},{"ID":"20250526173241-l9m1gb9","Type":"NodeHeading","HeadingLevel":3,"Properties":{"id":"20250526173241-l9m1gb9","updated":"20250526173241"},"Children":[{"Type":"NodeText","Data":"1. 效果（Effectiveness）"}]},{"ID":"20250526173241-s2roam2","Type":"NodeList","ListData":{},"Properties":{"id":"20250526173241-s2roam2","updated":"20250526173241"},"Children":[{"ID":"20250526173241-8jjjufn","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250526173241-8jjjufn","updated":"20250526173241"},"Children":[{"ID":"20250526173241-zhc86ib","Type":"NodeParagraph","Properties":{"id":"20250526173241-zhc86ib","updated":"20250526173241"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"准确率（Accuracy）"},{"Type":"NodeText","Data":"\n最常用的整体正确率指标。"}]}]},{"ID":"20250526173241-1aktkcd","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250526173241-1aktkcd","updated":"20250526173241"},"Children":[{"ID":"20250526173241-9le0bgc","Type":"NodeParagraph","Properties":{"id":"20250526173241-9le0bgc","updated":"20250526173241"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"精确率（Precision）"},{"Type":"NodeText","Data":"\n"},{"Type":"NodeTextMark","TextMarkType":"inline-math","TextMarkInlineMathContent":"\\mathrm{Precision} = \\frac{\\mathrm{TP}}{\\mathrm{TP + FP}}"},{"Type":"NodeText","Data":"，尤其在关注“误报”代价较高时很重要。"}]}]},{"ID":"20250526173241-whuqe7c","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250526173241-whuqe7c","updated":"20250526173241"},"Children":[{"ID":"20250526173241-0gclysj","Type":"NodeParagraph","Properties":{"id":"20250526173241-0gclysj","updated":"20250526173241"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"召回率（Recall） / 召回率（Sensitivity）"},{"Type":"NodeText","Data":"\n"},{"Type":"NodeTextMark","TextMarkType":"inline-math","TextMarkInlineMathContent":"\\mathrm{Recall} = \\frac{\\mathrm{TP}}{\\mathrm{TP + FN}}"},{"Type":"NodeText","Data":"，当“漏报”代价较高时重点关注。"}]}]},{"ID":"20250526173241-3pkzk9c","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250526173241-3pkzk9c","updated":"20250526173241"},"Children":[{"ID":"20250526173241-fvq1q3i","Type":"NodeParagraph","Properties":{"id":"20250526173241-fvq1q3i","updated":"20250526173241"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"F1 分数"},{"Type":"NodeText","Data":"\n"},{"Type":"NodeTextMark","TextMarkType":"inline-math","TextMarkInlineMathContent":"F1 = 2 \\times \\frac{\\mathrm{Precision} \\times \\mathrm{Recall}}{\\mathrm{Precision} + \\mathrm{Recall}}"},{"Type":"NodeText","Data":"，平衡精确率与召回率的调和平均。"}]}]},{"ID":"20250526173241-dwf3gax","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250526173241-dwf3gax","updated":"20250526173241"},"Children":[{"ID":"20250526173241-uqcwxyo","Type":"NodeParagraph","Properties":{"id":"20250526173241-uqcwxyo","updated":"20250526173241"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"ROC-AUC"},{"Type":"NodeText","Data":"\n在二分类或多分类（OvR）场景下衡量分类器在不同阈值下的整体性能。"}]}]},{"ID":"20250526173241-36nrykk","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250526173241-36nrykk","updated":"20250526173241"},"Children":[{"ID":"20250526173241-k54inww","Type":"NodeParagraph","Properties":{"id":"20250526173241-k54inww","updated":"20250526173241"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"混淆矩阵"},{"Type":"NodeText","Data":"\n直观展示 TP/FP/FN/TN 的分布情况，帮助发现模型在哪些类别上表现不好。"}]}]}]},{"ID":"20250526173241-04zn6nr","Type":"NodeThematicBreak","Properties":{"id":"20250526173241-04zn6nr","updated":"20250526173241"}},{"ID":"20250526173241-zj10iap","Type":"NodeHeading","HeadingLevel":3,"Properties":{"id":"20250526173241-zj10iap","updated":"20250526173241"},"Children":[{"Type":"NodeText","Data":"2. 效率（Efficiency）"}]},{"ID":"20250526173241-reuaeds","Type":"NodeList","ListData":{},"Properties":{"id":"20250526173241-reuaeds","updated":"20250526173241"},"Children":[{"ID":"20250526173241-kmla165","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250526173241-kmla165","updated":"20250526173241"},"Children":[{"ID":"20250526173241-vzdr748","Type":"NodeParagraph","Properties":{"id":"20250526173241-vzdr748","updated":"20250526173241"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"训练时间"}]},{"ID":"20250526173241-fmstyyi","Type":"NodeList","ListData":{},"Properties":{"id":"20250526173241-fmstyyi","updated":"20250526173241"},"Children":[{"ID":"20250526173241-43mucpt","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250526173241-43mucpt","updated":"20250526173241"},"Children":[{"ID":"20250526173241-uki4bu2","Type":"NodeParagraph","Properties":{"id":"20250526173241-uki4bu2","updated":"20250526173241"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"总训练耗时"},{"Type":"NodeText","Data":"（整个跑完所有 epoch 的时间）"}]}]},{"ID":"20250526173241-hcqp24j","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250526173241-hcqp24j","updated":"20250526173241"},"Children":[{"ID":"20250526173241-wn519k5","Type":"NodeParagraph","Properties":{"id":"20250526173241-wn519k5","updated":"20250526173241"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"单 epoch 平均时间"}]}]}]}]},{"ID":"20250526173241-ysolfqw","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250526173241-ysolfqw","updated":"20250526173241"},"Children":[{"ID":"20250526173241-qil2znt","Type":"NodeParagraph","Properties":{"id":"20250526173241-qil2znt","updated":"20250526173241"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"推理（Inference）时延（Latency）"}]},{"ID":"20250526173241-7zxnw70","Type":"NodeList","ListData":{},"Properties":{"id":"20250526173241-7zxnw70","updated":"20250526173241"},"Children":[{"ID":"20250526173241-5k74lmj","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250526173241-5k74lmj","updated":"20250526173241"},"Children":[{"ID":"20250526173241-fhr32eu","Type":"NodeParagraph","Properties":{"id":"20250526173241-fhr32eu","updated":"20250526173241"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"单样本平均推理时间"},{"Type":"NodeText","Data":"（ms/sample）"}]}]},{"ID":"20250526173241-tr01req","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250526173241-tr01req","updated":"20250526173241"},"Children":[{"ID":"20250526173241-yzsvhqt","Type":"NodeParagraph","Properties":{"id":"20250526173241-yzsvhqt","updated":"20250526173241"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"批推理时延"}]}]}]}]},{"ID":"20250526173241-kadxawf","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250526173241-kadxawf","updated":"20250526173241"},"Children":[{"ID":"20250526173241-b4swwan","Type":"NodeParagraph","Properties":{"id":"20250526173241-b4swwan","updated":"20250526173241"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"吞吐量（Throughput）"}]},{"ID":"20250526173241-036e58e","Type":"NodeList","ListData":{},"Properties":{"id":"20250526173241-036e58e","updated":"20250526173241"},"Children":[{"ID":"20250526173241-bttix73","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250526173241-bttix73","updated":"20250526173241"},"Children":[{"ID":"20250526173241-xm1aj2y","Type":"NodeParagraph","Properties":{"id":"20250526173241-xm1aj2y","updated":"20250526173241"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"样本/秒"},{"Type":"NodeText","Data":"（images/sec），在实际部署时尤其重要。"}]}]}]}]},{"ID":"20250526173241-krtyh1p","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250526173241-krtyh1p","updated":"20250526173241"},"Children":[{"ID":"20250526173241-blyzut7","Type":"NodeParagraph","Properties":{"id":"20250526173241-blyzut7","updated":"20250526173241"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"收敛速度"}]},{"ID":"20250526173241-rs1ypz4","Type":"NodeList","ListData":{},"Properties":{"id":"20250526173241-rs1ypz4","updated":"20250526173241"},"Children":[{"ID":"20250526173241-gogtg6c","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250526173241-gogtg6c","updated":"20250526173241"},"Children":[{"ID":"20250526173241-4jet3q1","Type":"NodeParagraph","Properties":{"id":"20250526173241-4jet3q1","updated":"20250526173241"},"Children":[{"Type":"NodeText","Data":"以达到同等准确率所需的 epoch 数或迭代次数衡量。"}]}]}]}]}]},{"ID":"20250526173241-8xmk8ff","Type":"NodeThematicBreak","Properties":{"id":"20250526173241-8xmk8ff","updated":"20250526173241"}},{"ID":"20250526173241-k8dbt0r","Type":"NodeHeading","HeadingLevel":3,"Properties":{"id":"20250526173241-k8dbt0r","updated":"20250529160620"},"Children":[{"Type":"NodeText","Data":"3. 资源消耗（Resource Consumption）"}]},{"ID":"20250526173241-ojs2efg","Type":"NodeList","ListData":{},"Properties":{"id":"20250526173241-ojs2efg","updated":"20250526173241"},"Children":[{"ID":"20250526173241-tsyrhv3","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250526173241-tsyrhv3","updated":"20250526173241"},"Children":[{"ID":"20250526173241-3ggujxm","Type":"NodeParagraph","Properties":{"id":"20250526173241-3ggujxm","updated":"20250526173241"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"显存使用量"}]},{"ID":"20250526173241-1bhe9rt","Type":"NodeList","ListData":{},"Properties":{"id":"20250526173241-1bhe9rt","updated":"20250526173241"},"Children":[{"ID":"20250526173241-s3nupv6","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250526173241-s3nupv6","updated":"20250526173241"},"Children":[{"ID":"20250526173241-mad4lo1","Type":"NodeParagraph","Properties":{"id":"20250526173241-mad4lo1","updated":"20250526173241"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"训练期间峰值 GPU 内存"}]}]},{"ID":"20250526173241-j4yug7e","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250526173241-j4yug7e","updated":"20250526173241"},"Children":[{"ID":"20250526173241-984h6m2","Type":"NodeParagraph","Properties":{"id":"20250526173241-984h6m2","updated":"20250526173241"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"推理期间所需内存"}]}]}]}]},{"ID":"20250526173241-o0uwgne","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250526173241-o0uwgne","updated":"20250526173241"},"Children":[{"ID":"20250526173241-y48m80j","Type":"NodeParagraph","Properties":{"id":"20250526173241-y48m80j","updated":"20250526173241"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"CPU / GPU 利用率"}]}]},{"ID":"20250526173241-393jreq","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250526173241-393jreq","updated":"20250526173241"},"Children":[{"ID":"20250526173241-ey53jwb","Type":"NodeParagraph","Properties":{"id":"20250526173241-ey53jwb","updated":"20250526173241"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"模型大小"}]},{"ID":"20250526173241-ctz0p1x","Type":"NodeList","ListData":{},"Properties":{"id":"20250526173241-ctz0p1x","updated":"20250526173241"},"Children":[{"ID":"20250526173241-mbzm4vd","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250526173241-mbzm4vd","updated":"20250526173241"},"Children":[{"ID":"20250526173241-dvsn1qm","Type":"NodeParagraph","Properties":{"id":"20250526173241-dvsn1qm","updated":"20250526173241"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"磁盘存储大小"},{"Type":"NodeText","Data":"（MB），影响部署与加载速度。"}]}]}]}]},{"ID":"20250526173241-tauvhk6","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250526173241-tauvhk6","updated":"20250526173241"},"Children":[{"ID":"20250526173241-bf3t1zo","Type":"NodeParagraph","Properties":{"id":"20250526173241-bf3t1zo","updated":"20250526173241"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"参数量（Params count）"}]},{"ID":"20250526173241-7kh85g0","Type":"NodeList","ListData":{},"Properties":{"id":"20250526173241-7kh85g0","updated":"20250526173241"},"Children":[{"ID":"20250526173241-1ef3mjv","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250526173241-1ef3mjv","updated":"20250526173241"},"Children":[{"ID":"20250526173241-24c6z35","Type":"NodeParagraph","Properties":{"id":"20250526173241-24c6z35","updated":"20250526173241"},"Children":[{"Type":"NodeText","Data":"总参数个数，以及可训练参数的数量。"}]}]}]}]},{"ID":"20250526173241-jqyu8u1","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250526173241-jqyu8u1","updated":"20250526173241"},"Children":[{"ID":"20250526173241-5ezvz82","Type":"NodeParagraph","Properties":{"id":"20250526173241-5ezvz82","updated":"20250526173241"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"计算量（FLOPs）"}]},{"ID":"20250526173241-kph3urc","Type":"NodeList","ListData":{},"Properties":{"id":"20250526173241-kph3urc","updated":"20250526173241"},"Children":[{"ID":"20250526173241-vyrexxc","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250526173241-vyrexxc","updated":"20250526173241"},"Children":[{"ID":"20250526173241-vr6nwuq","Type":"NodeParagraph","Properties":{"id":"20250526173241-vr6nwuq","updated":"20250526173241"},"Children":[{"Type":"NodeText","Data":"每次前向传播的大致浮点运算量。"}]}]}]}]},{"ID":"20250526173241-6rry7bb","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250526173241-6rry7bb","updated":"20250526173241"},"Children":[{"ID":"20250526173241-x4cldh2","Type":"NodeParagraph","Properties":{"id":"20250526173241-x4cldh2","updated":"20250526173241"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"能耗"},{"Type":"NodeText","Data":"（在对能效有严格要求的场景下）"}]}]}]},{"ID":"20250529160603-c49svw5","Type":"NodeParagraph","Properties":{"id":"20250529160603-c49svw5","updated":"20250529160603"}},{"ID":"20250529160619-ste6ti7","Type":"NodeHeading","HeadingLevel":1,"Properties":{"id":"20250529160619-ste6ti7","updated":"20250529160606"},"Children":[{"Type":"NodeText","Data":"深度学习系统运行时性能问题分析"}]},{"ID":"20250529160606-s374jv0","Type":"NodeHeading","HeadingLevel":3,"Properties":{"id":"20250529160606-s374jv0","updated":"20250529160606"},"Children":[{"Type":"NodeText","Data":"1. 环境设置"}]},{"ID":"20250529160606-ulsb62x","Type":"NodeParagraph","Properties":{"id":"20250529160606-ulsb62x","updated":"20250529160606"},"Children":[{"Type":"NodeText","Data":"硬件或系统环境配置不当常常造成性能瓶颈。例如，显卡驱动、CUDA 和 cuDNN 版本不兼容会导致 GPU 无法正常使用，系统退回到 CPU 执行而大幅降低速度"},{"Type":"NodeTextMark","TextMarkType":"a","TextMarkAHref":"https://blog.csdn.net/All_In_gzx_cc/article/details/126126297#:~:text=,26%E7%9A%84%E9%A9%B1%E5%8A%A8%EF%BC%8C%E5%90%8E%E6%9D%A5%E6%88%91%E6%8A%8ATITAN%20X%20%28Pascal%29%E8%A3%85%E4%B8%8A%E5%8E%BB%EF%BC%8C%E4%B8%80%E6%A0%B7%E5%8F%AF%E4%BB%A5%E6%AD%A3%E5%B8%B8%E7%94%A8%EF%BC%8C%E4%B8%8D%E9%9C%80%E8%A6%81%E9%92%88%E5%AF%B9TITAN%E9%87%8D%E8%A3%85%E9%A9%B1%E5%8A%A8%E3%80%82%E4%BD%86%E6%98%AF%E6%88%91%E4%B8%BA%E4%BA%86%E6%94%AF%E6%8C%81cu","TextMarkTextContent":"blog.csdn.net"},{"Type":"NodeText","Data":"。此外，如果所用 BLAS 库（如 OpenBLAS、Intel MKL）未启用硬件加速，也会影响 CPU 计算效率。容器化或虚拟化环境若未正确配置（如未启用 NVIDIA-Docker），可能引入额外开销。最后，GPU 资源不足（显存不够）会导致频繁的数据交换，影响训练和推理速度。"}]},{"ID":"20250529160606-x0e4g23","Type":"NodeList","ListData":{},"Properties":{"id":"20250529160606-x0e4g23","updated":"20250529160606"},"Children":[{"ID":"20250529160606-tfegqek","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250529160606-tfegqek","updated":"20250529160606"},"Children":[{"ID":"20250529160606-l58bh19","Type":"NodeParagraph","Properties":{"id":"20250529160606-l58bh19","updated":"20250529160606"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"检测方法："},{"Type":"NodeText","Data":" 通过 "},{"Type":"NodeTextMark","TextMarkType":"code","TextMarkTextContent":"nvidia-smi"},{"Type":"NodeText","Data":"​ 命令可实时查看 GPU 利用率、显存占用、温度等指标，判断 GPU 是否被充分利用"},{"Type":"NodeTextMark","TextMarkType":"a","TextMarkAHref":"https://blog.csdn.net/qq_29707567/article/details/125159494#:~:text=Image%20%E6%9C%AC%E6%96%87%E4%BB%8B%E7%BB%8D%E4%BA%86%E5%A4%9A%E7%A7%8D%E7%94%A8%E4%BA%8E%E7%9B%91%E6%8E%A7GPU%E7%8A%B6%E6%80%81%E7%9A%84%E5%91%BD%E4%BB%A4%E8%A1%8C%E5%B7%A5%E5%85%B7%EF%BC%8C%E5%A6%82nvidia","TextMarkTextContent":"blog.csdn.net"},{"Type":"NodeText","Data":"。使用 "},{"Type":"NodeTextMark","TextMarkType":"code","TextMarkTextContent":"top"},{"Type":"NodeText","Data":"​/"},{"Type":"NodeTextMark","TextMarkType":"code","TextMarkTextContent":"htop"},{"Type":"NodeText","Data":"​ 等系统工具监控 CPU 使用率和内存占用。确认深度学习框架启动日志中已识别到 GPU 设备。可以使用 NVIDIA Nsight Systems/Compute 等工具进行跨 CPU/GPU 的系统级性能分析"},{"Type":"NodeTextMark","TextMarkType":"a","TextMarkAHref":"https://help.aliyun.com/zh/ack/cloud-native-ai-suite/use-cases/using-nsight-system-to-realize-performance-analysis#:~:text=NVIDIA%20%E6%8F%90%E4%BE%9B%E4%BA%86%E4%B8%80%E4%BA%9B%E9%80%82%E7%94%A8%E4%BA%8E%20CUDA%20%E5%B1%82%E9%9D%A2%E7%9A%84%20Profiling,Systems%E3%80%81Nsight%20Compute%20%E5%92%8C%20Nsight%20Graphics%E3%80%82","TextMarkTextContent":"help.aliyun.com"},{"Type":"NodeText","Data":"。如果发现 GPU 利用率长期很低而 CPU/I/O 瓶颈突出，说明环境配置可能存在问题。"}]}]},{"ID":"20250529160606-ha7q66l","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250529160606-ha7q66l","updated":"20250529160606"},"Children":[{"ID":"20250529160606-g1x3s6c","Type":"NodeParagraph","Properties":{"id":"20250529160606-g1x3s6c","updated":"20250529160606"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"优化策略："},{"Type":"NodeText","Data":" 保持显卡驱动、CUDA 与深度学习框架版本兼容，新驱动一般向下兼容旧 CUDA"},{"Type":"NodeTextMark","TextMarkType":"a","TextMarkAHref":"https://blog.csdn.net/All_In_gzx_cc/article/details/126126297#:~:text=,26%E7%9A%84%E9%A9%B1%E5%8A%A8%EF%BC%8C%E5%90%8E%E6%9D%A5%E6%88%91%E6%8A%8ATITAN%20X%20%28Pascal%29%E8%A3%85%E4%B8%8A%E5%8E%BB%EF%BC%8C%E4%B8%80%E6%A0%B7%E5%8F%AF%E4%BB%A5%E6%AD%A3%E5%B8%B8%E7%94%A8%EF%BC%8C%E4%B8%8D%E9%9C%80%E8%A6%81%E9%92%88%E5%AF%B9TITAN%E9%87%8D%E8%A3%85%E9%A9%B1%E5%8A%A8%E3%80%82%E4%BD%86%E6%98%AF%E6%88%91%E4%B8%BA%E4%BA%86%E6%94%AF%E6%8C%81cu","TextMarkTextContent":"blog.csdn.net"},{"Type":"NodeText","Data":"。优先使用 GPU 进行计算（通过设置 "},{"Type":"NodeTextMark","TextMarkType":"code","TextMarkTextContent":"CUDA_VISIBLE_DEVICES"},{"Type":"NodeText","Data":"​ 等环境变量），并使用高效的数学库（如启用 MKL-DNN、cuDNN、cuBLAS 等）。在 CPU 上运行时，采用多线程并行（如 OpenMP/Intel MKL 线程）以充分利用多核。确保机器内存充足、关闭节能模式避免降频。容器中运行时使用 NVIDIA 容器工具包以正确挂载 GPU，或在条件允许下直接裸机部署以减少虚拟化开销。"}]}]}]},{"ID":"20250529160606-y849a84","Type":"NodeHeading","HeadingLevel":3,"Properties":{"id":"20250529160606-y849a84","updated":"20250529160606"},"Children":[{"Type":"NodeText","Data":"2. 初始化"}]},{"ID":"20250529160606-brxesbm","Type":"NodeParagraph","Properties":{"id":"20250529160606-brxesbm","updated":"20250529160606"},"Children":[{"Type":"NodeText","Data":"首次运行时的图构建和资源分配会引入额外开销。静态图框架（如 TensorFlow）需要编译计算图，动态框架（如 PyTorch）需要进行 CUDA 内核调度和 Python 解析。这些操作通常发生在训练开始的前几个批次，导致这些批次明显比后续批次耗时更长。如果不剔除这部分开销，性能分析结果可能失真"},{"Type":"NodeTextMark","TextMarkType":"a","TextMarkAHref":"https://www.tensorflow.org/guide/profiler?hl=zh-cn#:~:text=%E4%B8%AA%E6%AD%A5%E9%AA%A4%E7%9A%84%E6%80%A7%E8%83%BD%E3%80%82%E4%B8%BA%E4%BA%86%E9%81%BF%E5%85%8D%E7%94%B1%E5%88%9D%E5%A7%8B%E5%8C%96%E5%BC%80%E9%94%80%E5%AF%BC%E8%87%B4%E7%9A%84%E4%B8%8D%E5%87%86%E7%A1%AE%EF%BC%8C%E8%AF%B7%E4%B8%8D%E8%A6%81%E5%89%96%E6%9E%90%E5%89%8D%E5%87%A0%E4%B8%AA%E6%89%B9%E6%AC%A1%E7%9A%84%E6%80%A7%E8%83%BD%E3%80%82","TextMarkTextContent":"tensorflow.org"},{"Type":"NodeText","Data":"。模型参数的随机初始化和优化器等组件的构建也会在开始阶段带来开销。"}]},{"ID":"20250529160606-x301f2l","Type":"NodeList","ListData":{},"Properties":{"id":"20250529160606-x301f2l","updated":"20250529160606"},"Children":[{"ID":"20250529160606-8ftx801","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250529160606-8ftx801","updated":"20250529160606"},"Children":[{"ID":"20250529160606-17p2qlb","Type":"NodeParagraph","Properties":{"id":"20250529160606-17p2qlb","updated":"20250529160606"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"检测方法："},{"Type":"NodeText","Data":" 对比训练过程中前几个步骤与后续步骤的耗时，或使用框架的 Profiler 工具（如 TensorBoard Profiler、PyTorch Profiler）观察是否存在明显的初始化延迟。TensorFlow 文档建议在性能分析时跳过前几个批次，以避免初始化开销的影响"},{"Type":"NodeTextMark","TextMarkType":"a","TextMarkAHref":"https://www.tensorflow.org/guide/profiler?hl=zh-cn#:~:text=%E4%B8%AA%E6%AD%A5%E9%AA%A4%E7%9A%84%E6%80%A7%E8%83%BD%E3%80%82%E4%B8%BA%E4%BA%86%E9%81%BF%E5%85%8D%E7%94%B1%E5%88%9D%E5%A7%8B%E5%8C%96%E5%BC%80%E9%94%80%E5%AF%BC%E8%87%B4%E7%9A%84%E4%B8%8D%E5%87%86%E7%A1%AE%EF%BC%8C%E8%AF%B7%E4%B8%8D%E8%A6%81%E5%89%96%E6%9E%90%E5%89%8D%E5%87%A0%E4%B8%AA%E6%89%B9%E6%AC%A1%E7%9A%84%E6%80%A7%E8%83%BD%E3%80%82","TextMarkTextContent":"tensorflow.org"},{"Type":"NodeText","Data":"。如果前几个步骤耗时远超平均水平，即可判断存在初始化瓶颈。"}]}]},{"ID":"20250529160606-yj3tk0q","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250529160606-yj3tk0q","updated":"20250529160606"},"Children":[{"ID":"20250529160606-jf9zka5","Type":"NodeParagraph","Properties":{"id":"20250529160606-jf9zka5","updated":"20250529160606"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"优化策略："},{"Type":"NodeText","Data":" 采用“预热”步骤（warm-up），在正式计时前先进行一次空输入或小批量数据的前向传播，以提前分配显存和优化计算图。对于 TensorFlow，可使用 "},{"Type":"NodeTextMark","TextMarkType":"code","TextMarkTextContent":"model.build(input_shape)"},{"Type":"NodeText","Data":"​ 或在 "},{"Type":"NodeTextMark","TextMarkType":"code","TextMarkTextContent":"@tf.function(jit_compile=True)"},{"Type":"NodeText","Data":"​ 下运行，提前构建并编译图；对于 PyTorch，可使用 TorchScript（"},{"Type":"NodeTextMark","TextMarkType":"code","TextMarkTextContent":"torch.jit.trace"},{"Type":"NodeText","Data":"​/"},{"Type":"NodeTextMark","TextMarkType":"code","TextMarkTextContent":"script"},{"Type":"NodeText","Data":"​）生成静态图来减少 Python 解释开销。避免在每次训练中重复创建模型（例如在循环中不必要地重新实例化网络）。关闭非必要的日志输出和调试模式（如 Python 的调试断点、TensorFlow 的 "},{"Type":"NodeTextMark","TextMarkType":"code","TextMarkTextContent":"tf.debugging"},{"Type":"NodeText","Data":"​）以减少初始化时的额外开销。"}]}]}]},{"ID":"20250529160606-trdcz8a","Type":"NodeHeading","HeadingLevel":3,"Properties":{"id":"20250529160606-trdcz8a","updated":"20250529160606"},"Children":[{"Type":"NodeText","Data":"3. 数据准备"}]},{"ID":"20250529160606-dkgbwk4","Type":"NodeParagraph","Properties":{"id":"20250529160606-dkgbwk4","updated":"20250529160606"},"Children":[{"Type":"NodeText","Data":"数据加载与预处理往往是训练过程中隐藏的瓶颈。若数据从磁盘/网络读取速度慢，或图像/文本的解码、裁剪、归一化、增强等操作耗费大量 CPU 时间，就会导致 GPU 空闲等待"},{"Type":"NodeTextMark","TextMarkType":"a","TextMarkAHref":"https://help.aliyun.com/zh/ack/cloud-native-ai-suite/use-cases/use-pytorch-profiler-to-realize-performance-analysis-and-troubleshooting-of-large-models#:~:text=%E4%BC%98%E5%8C%96%E6%96%B9%E5%90%91%201%EF%BC%9A%E5%8A%A0%E9%80%9F%E6%95%B0%E6%8D%AE%E5%8A%A0%E8%BD%BD","TextMarkTextContent":"help.aliyun.com"},{"Type":"NodeText","Data":"。实践中发现，在只用 1 个数据加载线程（worker）时，一个训练 Step 的数据加载可能占总时间的近半"},{"Type":"NodeTextMark","TextMarkType":"a","TextMarkAHref":"https://help.aliyun.com/zh/ack/cloud-native-ai-suite/use-cases/use-pytorch-profiler-to-realize-performance-analysis-and-troubleshooting-of-large-models#:~:text=PyTorch%20%E7%9A%84%20DataLoader%20%E6%94%AF%E6%8C%81%E5%A4%9A%E4%B8%AA%20Worker%EF%BC%88Multi,Mini%20Batch%20%E7%9A%84%E6%95%B0%E6%8D%AE%E5%8A%A0%E8%BD%BD%E4%BB%BB%E5%8A%A1%E3%80%82","TextMarkTextContent":"help.aliyun.com"},{"Type":"NodeText","Data":"。此外，数据集过大且未使用缓存，或不当的文件格式（如大量小文件）也会增加 I/O 延迟。"}]},{"ID":"20250529160606-atr7nl6","Type":"NodeList","ListData":{},"Properties":{"id":"20250529160606-atr7nl6","updated":"20250529160606"},"Children":[{"ID":"20250529160606-rb9j8od","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250529160606-rb9j8od","updated":"20250529160606"},"Children":[{"ID":"20250529160606-u88lakx","Type":"NodeParagraph","Properties":{"id":"20250529160606-u88lakx","updated":"20250529160606"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"检测方法："},{"Type":"NodeText","Data":" 监测训练过程中的 GPU 与 CPU 利用率：如果 GPU 利用率低而 CPU 或磁盘 I/O 利用率高，说明数据管道成为瓶颈。使用深度学习框架的 Profiler（如 PyTorch Profiler 或 TensorFlow Profiler）量化数据加载的时间占比"},{"Type":"NodeTextMark","TextMarkType":"a","TextMarkAHref":"https://help.aliyun.com/zh/ack/cloud-native-ai-suite/use-cases/use-pytorch-profiler-to-realize-performance-analysis-and-troubleshooting-of-large-models#:~:text=PyTorch%20%E7%9A%84%20DataLoader%20%E6%94%AF%E6%8C%81%E5%A4%9A%E4%B8%AA%20Worker%EF%BC%88Multi,Mini%20Batch%20%E7%9A%84%E6%95%B0%E6%8D%AE%E5%8A%A0%E8%BD%BD%E4%BB%BB%E5%8A%A1%E3%80%82","TextMarkTextContent":"help.aliyun.com"},{"Type":"NodeText","Data":"。可视化 TensorBoard TimeLine 或使用 "},{"Type":"NodeTextMark","TextMarkType":"code","TextMarkTextContent":"torch.utils.bottleneck"},{"Type":"NodeText","Data":"​ 等工具查看每个 Step 中“数据加载 vs 前向/反向计算”的时间分布。也可以通过 "},{"Type":"NodeTextMark","TextMarkType":"code","TextMarkTextContent":"iostat"},{"Type":"NodeText","Data":"​、"},{"Type":"NodeTextMark","TextMarkType":"code","TextMarkTextContent":"iotop"},{"Type":"NodeText","Data":"​ 等系统工具监控磁盘吞吐。"}]}]},{"ID":"20250529160606-vw14015","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250529160606-vw14015","updated":"20250529160606"},"Children":[{"ID":"20250529160606-5jlcp9f","Type":"NodeParagraph","Properties":{"id":"20250529160606-5jlcp9f","updated":"20250529160606"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"优化策略："},{"Type":"NodeText","Data":" 启用并行数据加载：增加 DataLoader 的 worker 数量，使用多进程并行读取和预处理数据"},{"Type":"NodeTextMark","TextMarkType":"a","TextMarkAHref":"https://help.aliyun.com/zh/ack/cloud-native-ai-suite/use-cases/use-pytorch-profiler-to-realize-performance-analysis-and-troubleshooting-of-large-models#:~:text=PyTorch%20%E7%9A%84%20DataLoader%20%E6%94%AF%E6%8C%81%E5%A4%9A%E4%B8%AA%20Worker%EF%BC%88Multi,Mini%20Batch%20%E7%9A%84%E6%95%B0%E6%8D%AE%E5%8A%A0%E8%BD%BD%E4%BB%BB%E5%8A%A1%E3%80%82","TextMarkTextContent":"help.aliyun.com"},{"Type":"NodeText","Data":"。对数据进行预处理（如归一化、增强）时，尽量使用高效的批量操作或 C++/GPU 加速库。使用数据缓存：如将小数据集加载到内存，或将数据转换成高效的存储格式（TFRecord、LMDB、HDF5 等）以减少开销。对图像/视频数据，可使用 NVIDIA DALI 等库在 GPU 上进行解码和增强，这样可显著提高数据管道性能，避免 CPU 成为瓶颈"},{"Type":"NodeTextMark","TextMarkType":"a","TextMarkAHref":"https://developer.nvidia.com/zh-cn/blog/accelerating-medical-image-processing-with-dali/#:~:text=GPU%20%E5%8A%A0%E9%80%9F%E8%A7%A3%E5%86%B3%E6%96%B9%E6%A1%88","TextMarkTextContent":"developer.nvidia.com"},{"Type":"NodeText","Data":"。采用预取（prefetch）和异步读写，让 GPU 与数据加载并行：如使用 "},{"Type":"NodeTextMark","TextMarkType":"code","TextMarkTextContent":"tf.data.prefetch"},{"Type":"NodeText","Data":"​ 或 "},{"Type":"NodeTextMark","TextMarkType":"code","TextMarkTextContent":"DataLoader"},{"Type":"NodeText","Data":"​ 的 "},{"Type":"NodeTextMark","TextMarkType":"code","TextMarkTextContent":"pin_memory"},{"Type":"NodeText","Data":"​ 选项，使数据尽早准备完毕。"}]}]}]},{"ID":"20250529160606-mx0u6g6","Type":"NodeHeading","HeadingLevel":3,"Properties":{"id":"20250529160606-mx0u6g6","updated":"20250529160606"},"Children":[{"Type":"NodeText","Data":"4. 模型构建"}]},{"ID":"20250529160606-944ingi","Type":"NodeParagraph","Properties":{"id":"20250529160606-944ingi","updated":"20250529160606"},"Children":[{"Type":"NodeText","Data":"模型的结构设计和实现效率会直接影响运行速度。过度复杂或不合理的网络结构（如使用大量小卷积、重复的激活函数、完全连接层）会增加计算量和内存访问；模型参数过多也会导致显存开销和通信成本上升。如果模型定义中使用了 Python 循环或非向量化操作，则每次前后传导都会有额外的运算调度开销。此外，未充分利用硬件特性（如张量核心）或使用的库不高效，也会拖慢速度。"}]},{"ID":"20250529160606-gnahfxk","Type":"NodeList","ListData":{},"Properties":{"id":"20250529160606-gnahfxk","updated":"20250529160606"},"Children":[{"ID":"20250529160606-8hl4z6b","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250529160606-8hl4z6b","updated":"20250529160606"},"Children":[{"ID":"20250529160606-0db45cl","Type":"NodeParagraph","Properties":{"id":"20250529160606-0db45cl","updated":"20250529160606"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"检测方法："},{"Type":"NodeText","Data":" 分析模型各层运算情况：检查模型参数总量、每层参数大小及操作类型。使用 Profiler 检查每个操作的执行时间和资源占用，定位耗时最多的层或函数。可以在 PyTorch Profiler 或 TensorFlow Profiler 的报告中查看各操作（forward、backward）耗时；对 GPU 进行 Nsight Compute 分析，查看各 CUDA kernel 的执行效率和吞吐率。若发现某些小操作频繁调用或涉及大量内存读写，即为优化目标。"}]}]},{"ID":"20250529160606-ierkz9q","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250529160606-ierkz9q","updated":"20250529160606"},"Children":[{"ID":"20250529160606-pvb70mb","Type":"NodeParagraph","Properties":{"id":"20250529160606-pvb70mb","updated":"20250529160606"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"优化策略："},{"Type":"NodeText","Data":" 重构网络结构，使用并行度更高、计算更高效的模块。尽量使用框架提供的融合操作，例如卷积后直接接 BatchNorm 和激活函数（FuseConv+BatchNorm+ReLU），减少中间内存访问。对 TensorFlow 模型启用 XLA 编译器可以将多个运算融合成单个优化内核，避免中间结果写入内存"},{"Type":"NodeTextMark","TextMarkType":"a","TextMarkAHref":"https://www.tensorflow.org/xla?hl=zh-cn#:~:text=%E5%A6%82%E6%9E%9C%E5%9C%A8%E4%B8%8D%E4%BD%BF%E7%94%A8%20XLA%20%E7%9A%84%E6%83%85%E5%86%B5%E4%B8%8B%E8%BF%90%E8%A1%8C%EF%BC%8C%E5%9B%BE%E4%BC%9A%E5%90%AF%E5%8A%A8%E4%B8%89%E4%B8%AA%E5%86%85%E6%A0%B8%EF%BC%9A%E5%88%86%E5%88%AB%E5%AF%B9%E5%BA%94%E4%BA%8E%E4%B9%98%E6%B3%95%E3%80%81%E5%8A%A0%E6%B3%95%E5%92%8C%E5%87%8F%E6%B3%95%E8%BF%90%E7%AE%97%E3%80%82%E4%BD%86%E6%98%AF%EF%BC%8CXLA%20%E5%8F%AF%E4%BB%A5%E4%BC%98%E5%8C%96%E8%AF%A5%E5%9B%BE%EF%BC%8C%E4%BD%BF%E5%85%B6%E5%90%AF%E5%8A%A8%E4%B8%80%E6%AC%A1%E5%86%85%E6%A0%B8%E5%B0%B1%E8%83%BD%E8%AE%A1%E7%AE%97%E7%BB%93%E6%9E%9C%E3%80%82%E5%AE%83%E9%80%9A%E8%BF%87%E5%B0%86%E5%8A%A0%E6%B3%95%E3%80%81%E4%B9%98%E6%B3%95%E5%92%8C%E5%87%8F%E6%B3%95%E2%80%9C%E8%9E%8D%E5%90%88%E2%80%9D%E5%88%B0%E4%B8%80%E4%B8%AA%20GPU,GPU%20%E5%AF%84%E5%AD%98%E5%99%A8%E4%B8%AD%E3%80%82%E8%9E%8D%E5%90%88%E6%98%AF%20XLA%20%E9%87%87%E7%94%A8%E7%9A%84%E6%9C%80%E9%87%8D%E8%A6%81%E7%9A%84%E4%B8%80%E9%A1%B9%E4%BC%98%E5%8C%96%E6%8E%AA%E6%96%BD%E3%80%82%20%E5%86%85%E5%AD%98%E5%B8%A6%E5%AE%BD%E9%80%9A%E5%B8%B8%E6%98%AF%E7%A1%AC%E4%BB%B6%E5%8A%A0%E9%80%9F%E5%99%A8%E4%B8%8A%E6%9C%80%E7%A8%80%E7%BC%BA%E7%9A%84%E8%B5%84%E6%BA%90%EF%BC%8C%E5%9B%A0%E6%AD%A4%E6%B6%88%E9%99%A4%E5%86%85%E5%AD%98%E6%93%8D%E4%BD%9C%E6%98%AF%E6%8F%90%E9%AB%98%E6%80%A7%E8%83%BD%E7%9A%84%E6%9C%80%E4%BD%B3%E6%96%B9%E6%B3%95%E4%B9%8B%E4%B8%80%E3%80%82","TextMarkTextContent":"tensorflow.org"},{"Type":"NodeText","Data":"；实际上，在 V100 GPU 上启用 XLA 运行 BERT 模型时，速度可提升约 7 倍"},{"Type":"NodeTextMark","TextMarkType":"a","TextMarkAHref":"https://www.tensorflow.org/xla?hl=zh-cn#:~:text=XLA%EF%BC%88%E5%8A%A0%E9%80%9F%E7%BA%BF%E6%80%A7%E4%BB%A3%E6%95%B0%EF%BC%89%E6%98%AF%E4%B8%80%E7%A7%8D%E9%92%88%E5%AF%B9%E7%89%B9%E5%AE%9A%E9%A2%86%E5%9F%9F%E7%9A%84%E7%BA%BF%E6%80%A7%E4%BB%A3%E6%95%B0%E7%BC%96%E8%AF%91%E5%99%A8%EF%BC%8C%E8%83%BD%E5%A4%9F%E5%8A%A0%E5%BF%AB%20TensorFlow%20%E6%A8%A1%E5%9E%8B%E7%9A%84%E8%BF%90%E8%A1%8C%E9%80%9F%E5%BA%A6%EF%BC%8C%E8%80%8C%E4%B8%94%E5%8F%AF%E8%83%BD%E5%AE%8C%E5%85%A8%E4%B8%8D%E9%9C%80%E8%A6%81%E6%9B%B4%E6%94%B9%E6%BA%90%E4%BB%A3%E7%A0%81%E3%80%82","TextMarkTextContent":"tensorflow.org"},{"Type":"NodeText","Data":"。PyTorch 可使用 TorchScript 或其他 JIT 机制提前编译模型，减少 Python 调度开销。确保所有关键层使用高效的底层库（如 cuDNN、cuBLAS、oneDNN/MKL-DNN），并启用混合精度（FP16）以利用张量核心加速大规模矩阵乘法。对于推理场景，尽量剥离训练特有的节点（如 Dropout），简化计算图。"}]}]}]},{"ID":"20250529160606-g4oibug","Type":"NodeHeading","HeadingLevel":3,"Properties":{"id":"20250529160606-g4oibug","updated":"20250529160606"},"Children":[{"Type":"NodeText","Data":"5. 训练"}]},{"ID":"20250529160606-2jg4yum","Type":"NodeParagraph","Properties":{"id":"20250529160606-2jg4yum","updated":"20250529160606"},"Children":[{"Type":"NodeText","Data":"训练阶段的性能关键在于计算利用率和通信效率。常见瓶颈因素包括：Batch 过小导致 GPU 未充分负载；未启用混合精度训练，使每步计算量大；多卡/分布式训练时梯度同步或参数服务器的通信延迟；以及训练循环中不必要的同步操作。频繁保存检查点、打印日志或计算复杂指标也会增加开销。此外，使用复杂优化器（如未 Fuse 的 Adam）会引入额外计算。"}]},{"ID":"20250529160606-2jcap1u","Type":"NodeList","ListData":{},"Properties":{"id":"20250529160606-2jcap1u","updated":"20250529160606"},"Children":[{"ID":"20250529160606-4g4m5q6","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250529160606-4g4m5q6","updated":"20250529160606"},"Children":[{"ID":"20250529160606-hl7ekp2","Type":"NodeParagraph","Properties":{"id":"20250529160606-hl7ekp2","updated":"20250529160606"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"检测方法："},{"Type":"NodeText","Data":" 监控训练过程中的 GPU 利用率、每秒样本处理数（throughput）和每步耗时；使用 Profiler 工具（如 PyTorch Profiler、TensorFlow Profiler、NVIDIA Nsight Systems/Compute）捕获训练的详细时间线"},{"Type":"NodeTextMark","TextMarkType":"a","TextMarkAHref":"https://help.aliyun.com/zh/ack/cloud-native-ai-suite/use-cases/use-pytorch-profiler-to-realize-performance-analysis-and-troubleshooting-of-large-models#:~:text=PyTorch%20%E4%BD%9C%E4%B8%BA%E4%B8%80%E6%AC%BE%E5%BA%94%E7%94%A8%E4%BA%8E%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E9%A2%86%E5%9F%9F%E7%9A%84%E5%BA%93%EF%BC%8C%E5%85%B6%E5%BD%B1%E5%93%8D%E5%8A%9B%E6%97%A5%E7%9B%8A%E6%98%BE%E8%91%97%E3%80%82PyTorch%20Profiler%20%E6%98%AF%20PyTorch,Profiler%20API%20%E5%B7%B2%E8%A2%AB%E7%9B%B4%E6%8E%A5%E5%86%85%E7%BD%AE%E5%88%B0%20PyTorch%20%E6%A1%86%E6%9E%B6%E4%B8%AD%EF%BC%8C%E6%82%A8%E6%97%A0%E9%9C%80%E9%A2%9D%E5%A4%96%E5%AE%89%E8%A3%85%E5%85%B6%E4%BB%96%E8%BD%AF%E4%BB%B6%E5%8C%85%EF%BC%8C%E5%8D%B3%E5%8F%AF%E7%9B%B4%E6%8E%A5%E5%90%AF%E5%8A%A8%E6%A8%A1%E5%9E%8B%E5%88%86%E6%9E%90%E6%B5%81%E7%A8%8B%E3%80%82","TextMarkTextContent":"help.aliyun.com"},{"Type":"NodeText","Data":"。在 Profiler 报告或 TensorBoard Trace 中，检查前向传播、反向传播、参数更新和数据传输等阶段的耗时分布。如发现 GPU 利用率长期偏低或通信时间过长，即可判断训练过程存在瓶颈。对分布式训练，可开启 NCCL 或 MPI 的性能日志，分析多机/多卡通信的效率。"}]}]},{"ID":"20250529160606-h5v78yo","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250529160606-h5v78yo","updated":"20250529160606"},"Children":[{"ID":"20250529160606-s7703kq","Type":"NodeParagraph","Properties":{"id":"20250529160606-s7703kq","updated":"20250529160606"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"优化策略："},{"Type":"NodeText","Data":" 尽可能增大 BatchSize 提高吞吐量（需权衡显存和收敛）；启用混合精度训练（PyTorch 的 AMP、TensorFlow 的 "},{"Type":"NodeTextMark","TextMarkType":"code","TextMarkTextContent":"mixed_float16"},{"Type":"NodeText","Data":"​），利用半精度运算加速计算并减少显存使用。使用高效的分布式框架（如 PyTorch DistributedDataParallel 或 Horovod），将通信与计算重叠：在反向传播中发送梯度时，继续进行下一层的计算。选用高效的通信后端（NCCL）并调整通信优化参数；对于大型集群，可采用梯度压缩或大规模网络（如通信缓冲区）。避免训练循环中频繁进行阻塞操作，如大量打印或视觉化。调整优化器：例如使用经过 Fuse 的优化器版本或相对轻量的优化算法。增加数据加载并行度以匹配训练速度，减少数据成为瓶颈。"}]}]}]},{"ID":"20250529160606-v38q09h","Type":"NodeHeading","HeadingLevel":3,"Properties":{"id":"20250529160606-v38q09h","updated":"20250529160606"},"Children":[{"Type":"NodeText","Data":"6. 评估"}]},{"ID":"20250529160606-29v3kif","Type":"NodeParagraph","Properties":{"id":"20250529160606-29v3kif","updated":"20250529160606"},"Children":[{"Type":"NodeText","Data":"评估阶段将模型应用于验证集或测试集，虽然无反向传播，但仍可能出现性能问题。如果在评估过程中没有关闭梯度计算（未使用 "},{"Type":"NodeTextMark","TextMarkType":"code","TextMarkTextContent":"torch.no_grad()"},{"Type":"NodeText","Data":"​ 或等价机制），会浪费不必要的计算和内存。评估时的数据加载和预处理瓶颈与训练相似，也会导致 GPU 等待。计算复杂的评价指标（如大规模 mAP、召回率）本身也需要时间。如果每个 Epoch 后都对整个验证集进行评估，尤其是验证集很大时，可能显著拖慢整体训练速度。"}]},{"ID":"20250529160606-vf4stuq","Type":"NodeList","ListData":{},"Properties":{"id":"20250529160606-vf4stuq","updated":"20250529160606"},"Children":[{"ID":"20250529160606-zs1j3w4","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250529160606-zs1j3w4","updated":"20250529160606"},"Children":[{"ID":"20250529160606-ai4wfv9","Type":"NodeParagraph","Properties":{"id":"20250529160606-ai4wfv9","updated":"20250529160606"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"检测方法："},{"Type":"NodeText","Data":" 比较评估阶段的耗时与训练阶段的耗时，查看评估的 GPU/CPU 利用率。使用 Profiler 分析评估过程中各步骤耗时，检查是否仍在进行反向传播或不必要的数据复制。记录验证集上的计算时间，若与预期明显偏高，则需优化管道。也可监控内存占用，验证未在评估时开启梯度跟踪。"}]}]},{"ID":"20250529160606-1z4nft3","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250529160606-1z4nft3","updated":"20250529160606"},"Children":[{"ID":"20250529160606-4pm6e9i","Type":"NodeParagraph","Properties":{"id":"20250529160606-4pm6e9i","updated":"20250529160606"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"优化策略："},{"Type":"NodeText","Data":" 在评估时关闭梯度追踪（PyTorch 使用 "},{"Type":"NodeTextMark","TextMarkType":"code","TextMarkTextContent":"with torch.no_grad()"},{"Type":"NodeText","Data":"​，TensorFlow 使用 "},{"Type":"NodeTextMark","TextMarkType":"code","TextMarkTextContent":"tf.function"},{"Type":"NodeText","Data":"​ 或 "},{"Type":"NodeTextMark","TextMarkType":"code","TextMarkTextContent":"tf.stop_gradient"},{"Type":"NodeText","Data":"​），仅执行前向推理以节省计算资源。使用合理的 BatchSize 批量预测以提高 GPU 吞吐；对于过大的验证集，可采用数据抽样或降低评估频率来减少整体消耗。可以在不同资源上并行运行评估：如多GPU环境下，将一部分GPU专门用于评估，以避免与训练争抢资源。优化评估指标的计算实现，尽量避免不必要的计算和内存操作。"}]}]}]},{"ID":"20250529160606-s4dnkwh","Type":"NodeHeading","HeadingLevel":3,"Properties":{"id":"20250529160606-s4dnkwh","updated":"20250529160606"},"Children":[{"Type":"NodeText","Data":"7. 超参数调优"}]},{"ID":"20250529160606-5cxxqtw","Type":"NodeParagraph","Properties":{"id":"20250529160606-5cxxqtw","updated":"20250529160606"},"Children":[{"Type":"NodeText","Data":"超参数调优阶段通常涉及多次重复训练，容易成为整体流程的性能瓶颈。使用简单的网格搜索或穷举会产生大量训练任务，尤其是每次都要完全训练到结束时，效率很低。如果未使用提前停止机制，在模型效果不再改善时还继续训练，就会浪费资源。数据重复加载、模型重复构建等也会增加耗时。"}]},{"ID":"20250529160606-4zzqlvc","Type":"NodeList","ListData":{},"Properties":{"id":"20250529160606-4zzqlvc","updated":"20250529160606"},"Children":[{"ID":"20250529160606-t6ktlmh","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250529160606-t6ktlmh","updated":"20250529160606"},"Children":[{"ID":"20250529160606-mb913u4","Type":"NodeParagraph","Properties":{"id":"20250529160606-mb913u4","updated":"20250529160606"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"检测方法："},{"Type":"NodeText","Data":" 监控所有调参试验的总计算量和时间，记录各次试验的训练进度和性能曲线（可通过 TensorBoard、Weights \u0026 Biases、Ray Tune 等工具）。如果发现许多试验在达到可接受性能前就耗费了大量时间，或资源利用率低下，说明搜索策略或调度存在问题。跟踪每个试验的 GPU/CPU 使用情况，判断是否存在资源闲置。"}]}]},{"ID":"20250529160606-4xaol7i","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250529160606-4xaol7i","updated":"20250529160606"},"Children":[{"ID":"20250529160606-o1uqzws","Type":"NodeParagraph","Properties":{"id":"20250529160606-o1uqzws","updated":"20250529160606"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"优化策略："},{"Type":"NodeText","Data":" 采用更智能的搜索算法，例如随机搜索或贝叶斯优化（如 HyperOpt、Optuna）可以在较少的试验次数内找到较好的参数组合。引入中期评估和提前停止（如 Hyperband、ASHA）机制，对于效果不佳的超参数组合在训练中早期就停止。并行化超参搜索：将不同配置分配到多张 GPU 或多台服务器同时运行，加快整体搜索速度。对于大模型训练，可先在小数据集或小模型上快速筛选出大致范围，再在全量数据上细调。使用学习率调度、Warm-up 等技巧让模型更快收敛，减少单次训练时间。"}]}]}]},{"ID":"20250529160606-spqszco","Type":"NodeHeading","HeadingLevel":3,"Properties":{"id":"20250529160606-spqszco","updated":"20250529160606"},"Children":[{"Type":"NodeText","Data":"8. 预测"}]},{"ID":"20250529160606-1t5he8r","Type":"NodeParagraph","Properties":{"id":"20250529160606-1t5he8r","updated":"20250529160606"},"Children":[{"Type":"NodeText","Data":"推理阶段关注于使用训练好的模型进行快速预测，其性能指标常用延迟（latency）和吞吐量（throughput）。性能下降的因素包括："},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"批处理不充分"},{"Type":"NodeText","Data":"（一次只处理一个样本，每次调用都有固定开销）；"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"未使用硬件加速或低精度计算"},{"Type":"NodeText","Data":"（在可用 GPU 时却只用 CPU，或未使用 TensorRT/ONNX Runtime 等加速引擎）；"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"预处理开销"},{"Type":"NodeText","Data":"（如图像解码、归一化在 CPU 上耗时）；以及"},{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"模型加载和冷启动开销"},{"Type":"NodeText","Data":"（尤其在按需部署环境下，每次请求都要加载模型）。同时，多线程并发处理或网络通信不当也会导致响应延迟。"}]},{"ID":"20250529160606-pqj605z","Type":"NodeList","ListData":{},"Properties":{"id":"20250529160606-pqj605z","updated":"20250529160606"},"Children":[{"ID":"20250529160606-1gk6g2g","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250529160606-1gk6g2g","updated":"20250529160606"},"Children":[{"ID":"20250529160606-3xdfhda","Type":"NodeParagraph","Properties":{"id":"20250529160606-3xdfhda","updated":"20250529160606"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"检测方法："},{"Type":"NodeText","Data":" 测量推理延迟和吞吐量：记录单样本推理时间和多批处理推理时间，观察是否存在显著差异。使用 Profiler（如 TensorRT Profiler、ONNX Runtime 内置工具或 NVIDIA Nsight Systems）分析网络推理各层的耗时分布。监控推理时的硬件资源利用：若 GPU/CPU 利用率持续较低，说明计算或数据加载可能是瓶颈；反之若硬件满载但延迟高，则可能有架构问题。日志推理服务（如 Triton、TF Serving）时，可使用 Prometheus/Grafana 监控真实业务延迟和吞吐。"}]}]},{"ID":"20250529160606-afla1s5","Type":"NodeListItem","ListData":{"BulletChar":42,"Marker":"Kg=="},"Properties":{"id":"20250529160606-afla1s5","updated":"20250529160606"},"Children":[{"ID":"20250529160606-7lzsyce","Type":"NodeParagraph","Properties":{"id":"20250529160606-7lzsyce","updated":"20250529160606"},"Children":[{"Type":"NodeTextMark","TextMarkType":"strong","TextMarkTextContent":"优化策略："},{"Type":"NodeText","Data":" 导出模型并在高效推理引擎上运行：如使用 ONNX Runtime、TensorRT 或 OpenVINO 等，它们提供运算融合、内核优化和精度缩减等功能。应用模型量化（FP16/INT8）或蒸馏/剪枝技术减小模型大小，提高推理速度。尽可能启用批量推理（将多条请求合并处理）以提高吞吐量，并根据负载情况调整并发线程数。将输入预处理（图像解码、归一化等）并行化或在 GPU 上完成，减少 CPU 瓶颈。使用持久化部署服务保持模型常驻内存，避免频繁加载。对于 GPU 推理，NVIDIA TensorRT 可自动优化模型（融合层并选择最优内核），大幅降低推理时延、提升吞吐"},{"Type":"NodeTextMark","TextMarkType":"a","TextMarkAHref":"https://help.aliyun.com/zh/ack/cloud-native-ai-suite/use-cases/optimize-a-pytorch-model#:~:text=%E8%83%8C%E6%99%AF%E4%BF%A1%E6%81%AF","TextMarkTextContent":"help.aliyun.com"},{"Type":"NodeText","Data":"；对于 CPU 推理，可调整 ONNX Runtime 的 "},{"Type":"NodeTextMark","TextMarkType":"code","TextMarkTextContent":"run_options"},{"Type":"NodeText","Data":"​（如设备选择、线程数、预热迭代等）来获得更好性能"},{"Type":"NodeTextMark","TextMarkType":"a","TextMarkAHref":"https://cloud.baidu.com/article/3314888#:~:text=%E7%AE%80%E4%BB%8B%EF%BC%9AONNX%20Runtime%E6%98%AF%E4%B8%80%E7%A7%8D%E9%AB%98%E6%95%88%E7%9A%84%E8%BF%90%E8%A1%8C%E6%97%B6%E5%BA%93%EF%BC%8C%E9%80%82%E7%94%A8%E4%BA%8E%E5%90%84%E7%A7%8D%E7%A1%AC%E4%BB%B6%E3%80%82%E6%9C%AC%E6%96%87%E5%B0%86%E6%8C%87%E5%AF%BC%E8%AF%BB%E8%80%85%E5%A6%82%E4%BD%95%E9%80%9A%E8%BF%87%E8%B0%83%E6%95%B4run_options%E5%8F%82%E6%95%B0%E5%92%8C%E9%87%87%E7%94%A8%E5%85%B6%E4%BB%96%E4%BC%98%E5%8C%96%E7%AD%96%E7%95%A5%EF%BC%8C%E5%AE%9E%E7%8E%B0ONNX%20Runtime%E7%9A%84%E6%80%A7%E8%83%BD%E8%B0%83%E4%BC%98%EF%BC%8C%E6%8F%90%E9%AB%98%E6%A8%A1%E5%9E%8B%E8%BF%90%E8%A1%8C%E6%95%88%E7%8E%87%E3%80%82","TextMarkTextContent":"cloud.baidu.com"},{"Type":"NodeTextMark","TextMarkType":"a","TextMarkAHref":"https://cloud.baidu.com/article/3314888#:~:text=1","TextMarkTextContent":"cloud.baidu.com"},{"Type":"NodeText","Data":"。"}]}]}]}]}